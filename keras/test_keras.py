#utf-8
from __future__ import print_function
import keras
from keras.models import Sequential, load_model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.preprocessing import  image
import  numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
import random
import matplotlib as mpl
from matplotlib.image import imread
batch_size = 128
num_classes = 10
epochs = 12#æ¬¡æ•°
img_rows, img_cols = 28, 28
classs1 = {1:'ç‹—',0:'çŒ«'}
classes2={'cat':0,'dog':1}
"""
trainæ–‡ä»¶å¤¹ä¸‹
    0 : çŒ«ğŸ±
    1 : ç‹—ğŸ•
"""
#æ–‡ä»¶è½¬æ¢ä¸º np æ•°ç»„ ç”¨äºpredict
def image_file_nparray(image_path, width=100,height=100):
    img = image.load_img(image_path, target_size=(width,height))
    img = image.img_to_array(img)
    x = np.expand_dims(img, axis=0)
    return x
#è£å‰ªå•ä¸ªå›¾ç‰‡
def convert_one_image(file_path,width=100,height=100):
    img = Image.open(file_path)
    try:
        new_img = img.resize((width,height), Image.BILINEAR)
        new_img.save(file_path)
    except Exception as e:
        print("convert image error")
        print(e)
#å‰ªè£æ”¹ç›®å½•ä¸‹æ‰€æœ‰å›¾ç‰‡
#ç”¨äºäºŒçº§ç›®å½•
def convert_all_images(all_images_path):
    first_dir = os.listdir(all_images_path)

    for i in first_dir:
        _file_path = all_images_path + '/' + i
        if os.path.isdir(_file_path): #æ˜¯ç›®å½•    
            file_list = os.listdir(_file_path)
            for j in file_list:
                path_image = _file_path + '/' + j
                convert_one_image(path_image)  # è½¬æ¢
        else: #ä¸æ˜¯ç›®å½•, ç›´æ¥è½¬æ¢
            convert_one_image(_file_path)  # è½¬æ¢
# imageè½¬æ¢ä¸º np æ•°ç»„, ç”¨äº è®­ç»ƒæ¨¡å‹
def images_nparray(all_images_path):
    import os
    _x = []
    _y = []
    for i in os.listdir(all_images_path):
        _file_path = all_images_path+'/'+i
        if os.path.isdir(_file_path):#æ˜¯ç›®å½•

            for j in os.listdir(_file_path):
                y_label = j.split('_')[0]
                _y.append(y_label)

                path_image = _file_path +'/'+ j

                #å›¾ç‰‡åˆ°npæ•°ç»„
                img__ = Image.open(path_image).convert('RGB')
                img__ = np.array(img__)
                _x.append(img__)

        #ä¸æ˜¯ç›®å½•
        else:
            y_label = i.split('.')[0]
            y_label = classes2[y_label]
            print(y_label)
            _y.append(y_label)
            path_image = _file_path
            img__ = Image.open(path_image).convert('RGB')
            img__ = np.array(img__)
            _x.append(img__)
    return np.array(_x), np.array(_y)
# npæ•°ç»„ è½¬æ¢ä¸º npzæ–‡ä»¶
def nparray_to_npz(train_path, test_path,npz_file_path):
    convert_all_images(train_path)
    convert_all_images(test_path)
    x_train,y_train = images_nparray(train_path)
    x_test,y_test = images_nparray(test_path)
    #ä¿å­˜å‹ç¼©æ–‡ä»¶
    np.savez(npz_file_path, x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test)
#è®­ç»ƒå‡½æ•°
def running_train_test(npz_file_path, save_file_path):
    input_shape = (100,100,3)
    # the data, split between train and test sets
    data = np.load(npz_file_path)
    x_train, y_train, x_test, y_test = data['x_train'],data['y_train'],data['x_test'],data['y_test']

    x_train = x_train.astype('float32')
    x_test = x_test.astype('float32')
    x_train /= 255
    x_test /= 255
    print('x_train shape:', x_train.shape)
    print(x_train.shape[0], 'train samples')
    print(x_test.shape[0], 'test samples')
    # convert class vectors to binary class matrices
    y_train = keras.utils.to_categorical(y_train, num_classes)
    y_test = keras.utils.to_categorical(y_test, num_classes)

    model = Sequential()
    model.add(Conv2D(32, kernel_size=(3, 3),
                        activation='relu',
                        input_shape=input_shape))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))

    model.compile(loss=keras.losses.categorical_crossentropy,
                    optimizer=keras.optimizers.Adadelta(),
                    metrics=['accuracy'])


    hist = model.fit(x_train, y_train,
                batch_size=batch_size,
                epochs=epochs,
                verbose=1,
                validation_data=(x_test, y_test))
    score = model.evaluate(x_test, y_test, verbose=0)
    print('Test loss:', score[0])
    print('Test accuracy:', score[1])
    model.save(save_file_path) #ä¿å­˜
    #ç»˜å›¾
    plt.figure()
    print(hist.history)
    acc = hist.history['accuracy']
    val_acc = hist.history['val_accuracy']
    loss = hist.history['loss']
    val_loss = hist.history['val_loss']
    epochs2 = range(len(acc))
    plt.plot(epochs2, acc, 'bo', label='Training acc')  # 'bo'ä¸ºç”»è“è‰²åœ†ç‚¹ï¼Œä¸è¿çº¿
    plt.plot(epochs2, val_acc, 'b', label='Validation acc')
    plt.title('Training and validation accuracy')
    plt.legend()  # ç»˜åˆ¶å›¾ä¾‹ï¼Œé»˜è®¤åœ¨å³ä¸Šè§’
    plt.figure()
    plt.plot(epochs2, loss, 'bo', label='Training loss')
    plt.plot(epochs2, val_loss, 'b', label='Validation loss')
    plt.title('Training and validation loss')
    plt.legend()

    plt.show()

# è½¬æ¢ä¸è®­ç»ƒ
def train_test_images_to_model(train, test, npz_path, h5_path):
    nparray_to_npz(train,test,npz_path)
    running_train_test(npz_path,h5_path)
# ç”¨äºé¢„æµ‹
def load_model_from_h5_and_predict(h5_path, pre_path):
    model = load_model(h5_path)
    # convert_one_image(pre_path)
    pre_nparray = image_file_nparray(pre_path)
    pre_y = model.predict_classes(pre_nparray)
    print("ç»“æœ : ",classs1[pre_y[0]])
    return classs1[pre_y[0]]

def predict_one_file(model, pre_path):
    pre_nparray = image_file_nparray(pre_path)
    pre_y = model.predict_classes(pre_nparray)
    print("ç»“æœ : ", classs1[pre_y[0]])
    return classs1[pre_y[0]]
def predict_dir_images(h5_path, pre_path, num=10):
    model = load_model(h5_path)
    res = []
    mpl.rcParams['font.sans-serif'] = ['FangSong']  # æŒ‡å®šé»˜è®¤å­—ä½“
    mpl.rcParams['axes.unicode_minus'] = False  # è§£å†³ä¿å­˜å›¾åƒæ˜¯è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜
    for i in range  (num):
        imgpath =  random.randint(1,10000)
        imgpath = pre_path+"/"+str(imgpath)+".jpg"
        tmp = predict_one_file(model,imgpath)
        res.append({"file":imgpath,"result":tmp})
        img = imread(imgpath)
        plt.subplot(2,5,i+1)
        plt.title(imgpath+" : "+tmp)
        plt.imshow(img)
    return res
#mainå‡½æ•°...
if "__main__" == __name__:
    npz_path = 'cat_dog.npz'
    save_path = 'save.h5'
    test_dir_path = 'test'
    train_dir_path = 'train'
    # train_test_images_to_model(train_dir_path, test_dir_path, npz_path, save_path)
    pre = 'pre'
    res = predict_dir_images(save_path,pre)
    plt.show()
    print(res)
